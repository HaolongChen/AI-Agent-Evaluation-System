# Database
DATABASE_URL=postgresql://user:password@localhost:5432/evaluation_db
DATABASE_URL_PRODUCTION=postgresql://user:password@host:port/db
DATABASE_URL_DEVELOPMENT=postgresql://user:password@localhost:5432/db

# Server
PORT=4000
NODE_ENV=development
MODE=development

# Functorz Copilot WebSocket (REQUIRED)
# This is a base endpoint; the app will append userToken, projectExId, and clientType.
# Example: wss://zion.functorz.work/ws?
WS_URL=wss://your-functorz-endpoint/ws?
userToken=YOUR_USER_TOKEN
projectExId=YOUR_PROJECT_EX_ID
clientType=WEB

# Functorz Backend GraphQL (used by services, NOT the copilot websocket)
BACKEND_GRAPHQL_URL=https://zionbackend.functorz.work/api/graphql

# LLM API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
AZURE_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# IMPORTANT: This is the *deployment name* you created in Azure OpenAI Studio,
# not the base model id (e.g. not "gpt-4o-mini").
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2025-04-01-preview

# LLM Configuration
LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4o-mini
GEMINI_MODEL=gemini-2.5-pro
LLM_TEMPERATURE=0.2
LLM_MAX_OUTPUT_TOKENS=1024

# Optional: delegate rubric/evaluation resumes to Kubernetes Jobs
RUN_KUBERNETES_JOBS=false

# Copilot Integration
COPILOT_API_URL=http://localhost:3000/api
COPILOT_API_KEY=...

# Kubernetes Configuration
KUBERNETES_NAMESPACE=ai-evaluation
KUBERNETES_JOB_IMAGE=your-registry/evaluation-worker:latest
KUBERNETES_JOB_CPU_REQUEST=500m
KUBERNETES_JOB_MEMORY_REQUEST=1Gi
KUBERNETES_JOB_CPU_LIMIT=2000m
KUBERNETES_JOB_MEMORY_LIMIT=4Gi
KUBERNETES_JOB_BACKOFF_LIMIT=3
KUBERNETES_JOB_ACTIVE_DEADLINE_SECONDS=3600

# Authentication
JWT_SECRET=your-secret-key

# Logging
LOG_LEVEL=info
